{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e9f21ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import visualize\n",
    "import cluster_dbscan\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from classifier_net import classifier_network, create_network\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import db_settings\n",
    "import geopandas\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.affinity import scale\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5a3779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT ID, NUMBER_OF_TREES FROM lidar_proj.LIDAR_FILES WHERE FILE_NAME = '3dm_32_350_5648_1_nw'\n",
      "SELECT * FROM lidar_proj.trees WHERE city_ID=2 and LIDAR_FILE_ID=1040 ORDER BY id\n",
      "Empty DataFrame\n",
      "Columns: [ID, X, Y, CITY_ID, ID_GATTUNG, LIDAR_FILE_ID]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# map to \n",
    "db = db_settings.db()\n",
    "#kurve:\n",
    "las_file = 'Demo/Köln/3dm_32_350_5656_1_nw.las'\n",
    "las_name = \"3dm_32_350_5656_1_nw\"\n",
    "\n",
    "req = \"\"\"SELECT ID, NUMBER_OF_TREES FROM lidar_proj.LIDAR_FILES WHERE FILE_NAME = \\'\"\"\"+ las_name+\"\"\"\\'\"\"\"\n",
    "print(req)\n",
    "lidar_file_number = db.export_to_pandas(req)\n",
    "req =\"\"\"SELECT * FROM lidar_proj.trees WHERE city_ID=\"\"\" + str(2) +\"\"\" and LIDAR_FILE_ID=\"\"\"+str(lidar_file_number['ID'].values[0])+\"\"\" ORDER BY id\"\"\"\n",
    "print(req)\n",
    "trees =db.export_to_pandas(req)\n",
    "print(trees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "807fb8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  2022-07-25 00:06:58.062540\n",
      "selecting points to cluster by classification\n",
      "clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3317256/3317256 [00:09<00:00, 355836.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building dictionary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10045/10045 [01:54<00:00, 87.40it/s]\n"
     ]
    }
   ],
   "source": [
    "#las_file = 'Demo/3dm_32_362_5716_1_nw.las'\n",
    "#las_file = 'Demo/3dm_32_362_5710_1_nw.las'\n",
    "#las_file = 'Demo/3dm_32_370_5709_1_nw_classified.laz'\n",
    "\n",
    "\n",
    "las_cluster =laspy.read(las_file)\n",
    "las_color =laspy.read(las_file)\n",
    "cluster_dict,color_dict, indices_dict = cluster_dbscan.cluster_las(las_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca920119",
   "metadata": {},
   "outputs": [],
   "source": [
    "hull_dict = {}\n",
    "\n",
    "for key in cluster_dict.keys():\n",
    "    tree = np.array(cluster_dict[key]).transpose((1, 0))\n",
    "    x = tree[0]\n",
    "    y = tree[1]    \n",
    "    points_2d = np.array([x,y]).transpose()\n",
    "    if len(points_2d) > 150:\n",
    "                hull = ConvexHull(points_2d)\n",
    "                poly = Polygon(points_2d[hull.vertices])\n",
    "                poly = scale(poly, xfact=1.1,yfact=1.1)\n",
    "                hull_dict[key] = poly\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fefc1c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ID, X, Y, CITY_ID, ID_GATTUNG, LIDAR_FILE_ID, coords]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "trees['coords'] = np.array(zip(trees['X'],trees['Y']))\n",
    "trees['coords'] = trees['coords'].apply(Point)\n",
    "trees_df = geopandas.GeoDataFrame(trees, geometry='coords', crs=\"EPSG:25832\")\n",
    "print(trees)                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc7e0f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating joins\n",
      "Empty GeoDataFrame\n",
      "Columns: [ID, X, Y, CITY_ID, ID_GATTUNG, LIDAR_FILE_ID, coords, index_right, HULL_DICT_KEY]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "hulls_df = pandas.DataFrame({'HULL_DICT_KEY': hull_dict.keys(), 'coords': hull_dict.values()})\n",
    "hulls_df = geopandas.GeoDataFrame(hulls_df, geometry='coords', crs=\"EPSG:25832\")\n",
    "print(\"calculating joins\")\n",
    "intersections = geopandas.tools.sjoin(trees_df,hulls_df, op=\"intersects\", how='inner') #intersects\n",
    "print(intersections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50469c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10044/10044 [00:31<00:00, 322.68it/s]\n"
     ]
    }
   ],
   "source": [
    "#print(color_dict[0])\n",
    "k = np.unique(np.array(intersections.HULL_DICT_KEY))\n",
    "print(len(k))\n",
    "for key in tqdm(cluster_dict.keys()):\n",
    "    for i in indices_dict[key]:\n",
    "        las_cluster.points['red'][i] = color_dict[key][0]\n",
    "        las_cluster.points['green'][i]= color_dict[key][1]\n",
    "        las_cluster.points['blue'][i]= color_dict[key][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eaba6595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22745098 0.30980392 0.23529412]\n",
      " [0.20392157 0.28627451 0.21960784]\n",
      " [0.1254902  0.2        0.22352941]\n",
      " ...\n",
      " [0.59607843 0.56470588 0.76470588]\n",
      " [0.56470588 0.40784314 0.90196078]\n",
      " [0.59607843 0.56470588 0.76470588]]\n"
     ]
    }
   ],
   "source": [
    "visualize.plot_las_3d(las_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16c27255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize.plot_las_3d(las_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3d3872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8024/8024 [00:00<00:00, 24109.51it/s]\n"
     ]
    }
   ],
   "source": [
    "normalized_dict = {}\n",
    "for key in tqdm(cluster_dict.keys()):\n",
    "        points = np.array(cluster_dict[key])\n",
    "        x , y, z = points.transpose()\n",
    "        x = np.array(x)\n",
    "        x = x - np.min(x)\n",
    "        y = np.array(y)\n",
    "        y = y - np.min(y)\n",
    "        z = np.array(z)\n",
    "        z = z - np.min(z)\n",
    "        points = np.array([x,y,z]).transpose()\n",
    "        points = points/ np.max(points)   \n",
    "        normalized_dict[key] = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50b560b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (Compose, AsChannelFirst, AddChannel, Resize,ScaleIntensity, RandGaussianSharpen, SpatialPad, ToTensor, Zoom, LoadImage,RandScaleCrop,OneOf, RandHistogramShift,RandCoarseDropout,AddChannel,RandFlip,RandZoom, RandRotate,EnsureType,NormalizeIntensity, Flip,  RandAdjustContrast, RandGaussianSmooth,RandBiasField,RandStdShiftIntensity,  GaussianSharpen,RandGaussianNoise, HistogramNormalize, RandGibbsNoise, RandKSpaceSpikeNoise, Rotate, compose)\n",
    "\n",
    "\n",
    "network_path = \"0.75_in_e_157_network\"\n",
    "size = 128\n",
    "\n",
    "trans_load_image = Compose([\n",
    "             AsChannelFirst(),\n",
    "             ToTensor(),\n",
    "             Resize((size, size)),\n",
    "\n",
    "             EnsureType(),\n",
    "             ])\n",
    "\n",
    "fit_network_transform = Compose([\n",
    "                                ToTensor(),\n",
    "                                Resize((size, size)),\n",
    "                                ScaleIntensity(), \n",
    "                                EnsureType(),             \n",
    "                                AddChannel(),])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33d6d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "network = classifier_network(None, [1,2] )\n",
    "\n",
    "network.net.load_state_dict(torch.load(network_path))\n",
    "for key in normalized_dict.keys():\n",
    "    list_of_points =normalized_dict[key]\n",
    "\n",
    "    xz = np.zeros([256,256])        \n",
    "    yz = np.zeros([256,256])\n",
    "    xy = np.zeros([256,256])\n",
    "    list_of_points = (list_of_points * 255).astype(int)\n",
    "    for x,y ,z in list_of_points:\n",
    "            xz[255 -z][x] += y\n",
    "            yz[255- z][y] +=x\n",
    "            xy[255 - y][x] += z\n",
    "       \n",
    "    img = np.array([xz, yz, xy]).transpose()\n",
    "    m = np.max(img)\n",
    "    img = (img/m) * 255\n",
    "    img = Image.fromarray(np.uint8(img)).rotate(270)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    img = img/ 255\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    network.net.eval()\n",
    "    image = trans_load_image(img)\n",
    "    #image  = image.type(torch.int)\n",
    "    image = fit_network_transform(image.to(network.device) )   \n",
    "    pred = network.net(image.float()) \n",
    "    #pred = softmax(pred)\n",
    "    predictions[key] = pred.type(torch.int)\n",
    "    print(pred.type(torch.int))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b516dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e624474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76ea87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e4134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
