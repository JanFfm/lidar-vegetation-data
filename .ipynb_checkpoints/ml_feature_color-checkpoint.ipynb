{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c636d038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janja\\Desktop\\GitHub\\lidar-vegetation-data\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import db_settings\n",
    "import pyexasol\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "print(os.getcwd())\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9845218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(id):\n",
    "    family = dict_families[dict_gattung[id]['ID_FAMILIE']]\n",
    "    order = dict_order[family['ID_ORDNUNG']]\n",
    "    c = order['ID_KLASSE']\n",
    "    return c\n",
    "def get_order(id):\n",
    "    family = dict_families[dict_gattung[id]['ID_FAMILIE']]\n",
    "    o = family['ID_ORDNUNG']\n",
    "    return o\n",
    "def get_family(id):\n",
    "    f = dict_families[dict_gattung[id]['ID_FAMILIE']]\n",
    "    return f\n",
    "\n",
    "\n",
    "def scale_y(y):\n",
    "    \"\"\"translates a list of labels with unsorted numbers to a labeling starting with [0,1,2,...]\n",
    "\n",
    "    Args:\n",
    "        y (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    labels = np.unique(y)\n",
    "    y_new = [i for i in range(len(labels))]\n",
    "    translator = {key:value for (key,value) in zip(labels, y_new)}\n",
    "    re_translate = {key:value for (key,value) in zip(y_new, labels)}\n",
    "\n",
    "    y = [translator[i] for i in y]\n",
    "    return y, re_translate\n",
    "        \n",
    "         \n",
    "\n",
    "def train(X_train, X_test, y_train, y_test, weight=True):\n",
    "    if weight==True:\n",
    "        w = 'balanced'\n",
    "    else:\n",
    "        w=None\n",
    "    print(\"SVM linear Kernel:\")\n",
    "    svc_linear = SVC(kernel='linear', probability=True, class_weight=w)  #, class_weight='balanced'\n",
    "    svc_linear.fit(X_train, y_train)\n",
    "    y_pred = svc_linear.predict(X_test)\n",
    "    print(\"accuracy_score: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"balanced accuracy score\", balanced_accuracy_score(y_test, y_pred, adjusted=True))\n",
    "    print(\"SVM rbf kernel:\")\n",
    "    svc_rbf = SVC(kernel='rbf', probability=True, class_weight=w)\n",
    "    svc_rbf.fit(X_train, y_train)\n",
    "    y_pred = svc_rbf.predict(X_test)\n",
    "    print(\"accuracy_score: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"balanced accuracy score\", balanced_accuracy_score(y_test, y_pred, adjusted=True))\n",
    "    print(\"SVM poly kernel:\")\n",
    "    svc_poly = SVC(kernel='poly', probability=True, class_weight=w)\n",
    "    svc_poly.fit(X_train, y_train)\n",
    "    y_pred = svc_poly.predict(X_test)\n",
    "    print(\"accuracy_score: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"balanced accuracy score\", balanced_accuracy_score(y_test, y_pred, adjusted=True))\n",
    "    print(\"decission Tree\")\n",
    "    t = tree.DecisionTreeClassifier(class_weight=w)\n",
    "    t = t.fit(X_train, y_train)\n",
    "    print(\"accuracy_score: \", t.score(X_test, y_test))\n",
    "    print(\"balanced accuracy score\", balanced_accuracy_score(y_test, t.predict(X_test), adjusted=True))\n",
    "    print(\"decission tree depth=\", 20)\n",
    "    decision_tree = DecisionTreeClassifier(random_state=0, max_depth=29, class_weight=w)\n",
    "    decision_tree = decision_tree.fit(X_train, y_train)\n",
    "    print(\"accuracy_score: \", decision_tree.score(X_test, y_test))\n",
    "    print(\"balanced accuracy score\", balanced_accuracy_score(y_test, decision_tree.predict(X_test), adjusted=True))\n",
    "    #random forest:\n",
    "    print(\"random forest:\")\n",
    "    forest = RandomForestClassifier(n_estimators=500, class_weight=w)\n",
    "    forest.fit(X_train,y_train)\n",
    "    forest.predict(X_test)\n",
    "    forest.predict_proba(X_test)\n",
    "    print(\"accuracy_score: \", forest.score(X_test, y_test))\n",
    "    print(\"balanced accuracy score\", balanced_accuracy_score(y_test, forest.predict(X_test), adjusted=True))\n",
    "\n",
    "def get_data():\n",
    "    df = pd.read_csv('feature_list.csv')\n",
    "    labels_unedited = np.array(df['ID_GATTUNG'])\n",
    "    df =df.drop(columns=['ID_GATTUNG'])\n",
    "    features = []  \n",
    "    # Iterate over each row\n",
    "    for rows in df.itertuples():      \n",
    "        # append the list to the final list\n",
    "        features.append(list(rows[1:]))\n",
    "    return features, labels_unedited\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef109e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "db =db_settings.db(autocommit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51d1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_families = \"\"\"SELECT * FROM lidar_proj.familien\"\"\"\n",
    "req_order = \"\"\"SELECT * FROM lidar_proj.ordnungen\"\"\"\n",
    "req_class = \"\"\"SELECT * FROM lidar_proj.klassen\"\"\"\n",
    "req_gattung = \"\"\"SELECT * FROM lidar_proj.gattungen\"\"\"\n",
    "\n",
    "df_families = db.export_to_pandas(req_families)\n",
    "df_order = db.export_to_pandas(req_order)\n",
    "df_class = db.export_to_pandas(req_class)\n",
    "df_gattung = db.export_to_pandas(req_gattung)\n",
    "\n",
    "df_families.set_index(\"ID\", drop=True, inplace=True)\n",
    "df_order.set_index(\"ID\", drop=True, inplace=True)\n",
    "df_class.set_index(\"ID\", drop=True, inplace=True)\n",
    "df_gattung.set_index(\"ID\", drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8e8ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LAT_NAME': 'Abies', 'DT_NAME': ' \\tTannen ', 'ID_FAMILIE': 1}\n"
     ]
    }
   ],
   "source": [
    "global dict_gattung\n",
    "global dict_families\n",
    "global dict_order\n",
    "global dict_class\n",
    "\n",
    "dict_gattung =df_gattung.to_dict(orient=\"index\")\n",
    "\n",
    "dict_families =df_families.to_dict(orient=\"index\")\n",
    "dict_order =df_order.to_dict(orient=\"index\")\n",
    "dict_class =df_class.to_dict(orient=\"index\")\n",
    "print(dict_gattung[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4ca21f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LAT_NAME': 'Aesculus', 'DT_NAME': ' \\tRosskastanien  ', 'ID_FAMILIE': 2}\n",
      "{'LAT_NAME': 'Sapindaceae', 'DT_NAME': ' Seifenbaumgew√§chse ', 'ID_ORDNUNG': 4}\n",
      "{'LAT_NAME': 'Sapindales', 'DT_NAME': 'Seifenbaumartige ', 'ID_KLASSE': 1}\n",
      "{'LAT_NAME': 'Magnoliopsida', 'DT_NAME': ' Bedecktsamer'}\n"
     ]
    }
   ],
   "source": [
    "#luckup klasse\n",
    "gattungs_id = 3\n",
    "print(dict_gattung[gattungs_id])\n",
    "family = dict_families[dict_gattung[gattungs_id]['ID_FAMILIE']]\n",
    "print(family)\n",
    "order = dict_order[family['ID_ORDNUNG']]\n",
    "print(order)\n",
    "c = dict_class[order['ID_KLASSE']]\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baab671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fae1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c5d4048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34576  individuums in train/test-set\n",
      "{0: 34054, 1: 522}\n",
      "labels train set {0: 22818, 1: 347}\n",
      "labels test set {0: 11236, 1: 175}\n",
      "SVM linear Kernel:\n",
      "accuracy_score:  0.5669967575146788\n",
      "balanced accuracy score 0.16648273406906355\n",
      "SVM rbf kernel:\n",
      "accuracy_score:  0.9199894838313908\n",
      "balanced accuracy score 0.05807455627320346\n",
      "SVM spoly kernel:\n",
      "accuracy_score:  0.017001139251599334\n",
      "balanced accuracy score -0.00955957890454151\n",
      "decission Tree\n",
      "accuracy_score:  0.9705547278941372\n",
      "balanced accuracy score 0.053174490159182186\n",
      "decission tree depth= 20\n",
      "accuracy_score:  0.9426868810796599\n",
      "balanced accuracy score 0.09800132228042524\n",
      "random forest:\n",
      "accuracy_score:  0.9846639207781964\n",
      "balanced accuracy score 0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Klasifizierung nach Klasse\n",
    "unbalanciertes Set\n",
    "Ohne Farben\n",
    "   \n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#set labels to class-labels\n",
    "labels = np.array(list(map(get_class, labels_unedited)))\n",
    "\n",
    "#mappimg ginko as conifera\n",
    "labels = np.array(list(map(lambda x: 2 if x==3 else x, labels)))\n",
    "\n",
    "labels, _ =scale_y(labels)\n",
    "\n",
    "print(len(labels), \" individuums in train/test-set\")\n",
    "\n",
    "#count_labels \n",
    "l, l_num = np.unique(labels, return_counts=True)\n",
    "print(dict(zip(l, l_num)))\n",
    "\n",
    "labels = np.array(labels)\n",
    "features = np.array(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "l, l_num = np.unique(y_train, return_counts=True)\n",
    "print(\"labels train set\", dict(zip(l, l_num)))\n",
    "l, l_num = np.unique(y_test, return_counts=True)\n",
    "print(\"labels test set\", dict(zip(l, l_num)))\n",
    "train(X_train, X_test, y_train, y_test)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Outout:\n",
    "    34576  individuums in train/test-set\n",
    "{0: 34054, 1: 522}\n",
    "labels train set {0: 22818, 1: 347}\n",
    "labels test set {0: 11236, 1: 175}\n",
    "SVM linear Kernel:\n",
    "accuracy_score:  0.5669967575146788\n",
    "balanced accuracy score 0.16648273406906355\n",
    "SVM rbf kernel:\n",
    "accuracy_score:  0.9199894838313908\n",
    "balanced accuracy score 0.05807455627320346\n",
    "SVM spoly kernel:\n",
    "accuracy_score:  0.017001139251599334\n",
    "balanced accuracy score -0.00955957890454151\n",
    "decission Tree\n",
    "accuracy_score:  0.9705547278941372\n",
    "balanced accuracy score 0.053174490159182186\n",
    "decission tree depth= 20\n",
    "accuracy_score:  0.9426868810796599\n",
    "balanced accuracy score 0.09800132228042524\n",
    "random forest:\n",
    "accuracy_score:  0.9846639207781964\n",
    "balanced accuracy score 0.0   \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49eaf79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34576  individuums in train/test-set\n",
      "{0: 34054, 1: 372, 2: 150}\n",
      "(744, 160)\n",
      "(744,)\n",
      "labels train set {0.0: 269, 1.0: 289}\n",
      "labels test set {0.0: 103, 1.0: 83}\n",
      "SVM linear Kernel:\n",
      "accuracy_score:  0.6612903225806451\n",
      "balanced accuracy score 0.3415604164229733\n",
      "SVM rbf kernel:\n",
      "accuracy_score:  0.44623655913978494\n",
      "balanced accuracy score 0.0\n",
      "SVM spoly kernel:\n",
      "accuracy_score:  0.44623655913978494\n",
      "balanced accuracy score 0.0\n",
      "decission Tree\n",
      "accuracy_score:  0.6021505376344086\n",
      "balanced accuracy score 0.21604866066206574\n",
      "decission tree depth= 20\n",
      "accuracy_score:  0.6397849462365591\n",
      "balanced accuracy score 0.2886887355246226\n",
      "random forest:\n",
      "accuracy_score:  0.7096774193548387\n",
      "balanced accuracy score 0.43595742192069253\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Downsamplig Magniolopsida, droping gingko:\"\"\"\n",
    "features, labels_unedited =get_data()\n",
    "labels = np.array(list(map(get_class, labels_unedited)))\n",
    "#labels = np.array(list(map(lambda x: 2 if x==3 else x, labels)))\n",
    "\n",
    "#mappimg ginko as conifera\n",
    "print(len(labels), \" individuums in train/test-set\")\n",
    "\n",
    "labels, re_translator =scale_y(labels)\n",
    "#count_labels \n",
    "l, l_num = np.unique(labels, return_counts=True)\n",
    "print(dict(zip(l, l_num)))\n",
    "\n",
    "labels = np.array(labels)\n",
    "features = np.array(features)\n",
    "#downsamplig:\n",
    "features_0 = features[ labels == 0]\n",
    "features_1 = features[ labels == 1]\n",
    "features_2 = features[ labels == 2]\n",
    "\n",
    "#features_0_downsampled = np.random.choice(features_0, size=features_1.shape[0], replace=False)\n",
    "idx = np.random.randint(features_0.shape[0] -1, size=features_1.shape[0])\n",
    "features_0_downsampled =features_0[idx,:]\n",
    "\n",
    "labels_0 = np.zeros(len(features_0_downsampled))\n",
    "labels_1 = np.ones(len(features_1))\n",
    "\n",
    "features =np.concatenate((features_0_downsampled, features_1))\n",
    "labels = np.concatenate((labels_0, labels_1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "l, l_num = np.unique(y_train, return_counts=True)\n",
    "print(\"labels train set\", dict(zip(l, l_num)))\n",
    "l, l_num = np.unique(y_test, return_counts=True)\n",
    "print(\"labels test set\", dict(zip(l, l_num)))\n",
    "train(X_train, X_test, y_train, y_test, weight=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5868e69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(dict(zip(l, l_num)))\\nbig_orders =[(14, \\'Gingkoales\\'), (7, \\'Fagales\\'), (8 ,\\'Rosales\\'), (10, \\'Lamiales\\'), (6, \\'Fabales\\'), (24, \\'Malves\\'), (23, \\'Proteales\\'), (16, \\'Malphgiales\\') ]\\nfor order in big_orders:\\n    print(\"\")\\n    print(\"comparing coniferales (Nadelh√∂lzer) to \", order[1])\\n    order_id = order[0]\\n    print(order_id)\\n\\n    features_0 = features[labels == 3]\\n    features_1 = features[labels == int(order_id)]\\n    ma = max(len(features_0), len(features_1))\\n    mi = min(len(features_0), len(features_1))\\n    break\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ordungen: 3: Coniferales=371\n",
    "  6 Fabales= 2465\n",
    "24 Males: 8782\n",
    "23 Proteales: 3100\n",
    "16 Malphigiales: 456\n",
    "\"\"\"\n",
    "features, labels_unedited =get_data()\n",
    "labels = np.array(list(map(get_order, labels_unedited)))\n",
    "l, l_num = np.unique(labels, return_counts=True)\n",
    "print(features)\n",
    "print(labels)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4150e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(dict(zip(l, l_num)))\n",
    "big_orders =[(14, 'Gingkoales'), (7, 'Fagales'), (8 ,'Rosales'), (10, 'Lamiales'), (6, 'Fabales'), (24, 'Malves'), (23, 'Proteales'), (16, 'Malphgiales') ]\n",
    "for order in big_orders:\n",
    "    print(\"\")\n",
    "    print(\"comparing coniferales (Nadelh√∂lzer) to \", order[1])\n",
    "    order_id = order[0]\n",
    "    print(order_id)\n",
    "\n",
    "    features_0 = features[labels == 3]\n",
    "    features_1 = features[labels == int(order_id)]\n",
    "    ma = max(len(features_0), len(features_1))\n",
    "    mi = min(len(features_0), len(features_1))\n",
    "    break\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceef36ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34576  individuums in train/test-set\n",
      "{0: 372, 1: 8858, 2: 21, 3: 2465, 4: 5668, 5: 2681, 6: 1674, 7: 1, 8: 230, 9: 150, 10: 103, 11: 456, 12: 1, 13: 7, 14: 1, 15: 6, 16: 3100, 17: 8782}\n",
      "labels train set {0: 248, 1: 5955, 2: 16, 3: 1617, 4: 3832, 5: 1791, 6: 1111, 7: 1, 8: 148, 9: 99, 10: 66, 11: 327, 12: 1, 13: 3, 14: 1, 15: 4, 16: 2082, 17: 5863}\n",
      "labels test set {0: 124, 1: 2903, 2: 5, 3: 848, 4: 1836, 5: 890, 6: 563, 8: 82, 9: 51, 10: 37, 11: 129, 13: 4, 15: 2, 16: 1018, 17: 2919}\n",
      "SVM linear Kernel:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Klasifizierung nach Ordung\n",
    "unbalanciertes Set\n",
    "Ohne Farben   \n",
    "\"\"\"\n",
    "features, labels_unedited =get_data()\n",
    "\n",
    "labels = np.array(list(map(get_order, labels_unedited)))\n",
    "\n",
    "#mappimg ginko as conifera\n",
    "print(len(labels), \" individuums in train/test-set\")\n",
    "\n",
    "labels, _ =scale_y(labels)\n",
    "#count_labels \n",
    "l, l_num = np.unique(labels, return_counts=True)\n",
    "print(dict(zip(l, l_num)))\n",
    "\n",
    "labels = np.array(labels)\n",
    "features = np.array(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "l, l_num = np.unique(y_train, return_counts=True)\n",
    "print(\"labels train set\", dict(zip(l, l_num)))\n",
    "l, l_num = np.unique(y_test, return_counts=True)\n",
    "print(\"labels test set\", dict(zip(l, l_num)))\n",
    "\n",
    "train(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0913b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0076884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"jetzt nochmal mit up- und dwonsampling !!!\n",
    "Dann mit Farbe!\n",
    "Dann Convex Hull?\n",
    "\"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e459b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing point cloud:\n",
    "\n",
    "csv_folder ='clusters/dbscan'\n",
    "extension = '*.csv' \n",
    "features_list = []\n",
    "for file in tqdm(Path(csv_folder).glob(extension)):\n",
    "        df = pd.read_csv(file)\n",
    "        features_list.append(df)\n",
    "print(len(features_list), \" files imported\")\n",
    "individuals = []\n",
    "for df in tqdm(features_list):     \n",
    "        cluster_ids = np.unique(np.array(df['Cluster_ID']).astype(int))\n",
    "        for id in cluster_ids:\n",
    "                df_split =df[df['Cluster_ID'] == id]\n",
    "                individuals.append(df_split)\n",
    "print(len(individuals), \"trees imported\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "76bf2483b678de59cbf0077370db76c835ab763105ad01236cd339f7f9e10161"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
