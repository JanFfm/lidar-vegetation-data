{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7769625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janja\\Desktop\\GitHub\\lidar-vegetation-data\n",
      "{'LAT_NAME': 'Abies', 'DT_NAME': ' \\tTannen ', 'ID_FAMILIE': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import db_settings\n",
    "import pyexasol\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "print(os.getcwd())\n",
    "np.random.seed(1234)\n",
    "\n",
    "def get_class(id):\n",
    "    family = dict_families[dict_gattung[id]['ID_FAMILIE']]\n",
    "    order = dict_order[family['ID_ORDNUNG']]\n",
    "    c = order['ID_KLASSE']\n",
    "    return c\n",
    "def get_order(id):\n",
    "    family = dict_families[dict_gattung[id]['ID_FAMILIE']]\n",
    "    o = family['ID_ORDNUNG']\n",
    "    return o\n",
    "def get_family(id):\n",
    "    f = dict_gattung[id]['ID_FAMILIE']\n",
    "    return f\n",
    "\n",
    "\n",
    "def scale_y(y):\n",
    "    \"\"\"translates a list of labels with unsorted numbers to a labeling starting with [0,1,2,...]\n",
    "\n",
    "    Args:\n",
    "        y (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    labels = np.unique(y)\n",
    "    y_new = [i for i in range(len(labels))]\n",
    "    translator = {key:value for (key,value) in zip(labels, y_new)}\n",
    "    re_translate = {key:value for (key,value) in zip(y_new, labels)}\n",
    "\n",
    "    y = [translator[i] for i in y]\n",
    "    return y, re_translate\n",
    "        \n",
    "         \n",
    "\n",
    "def train(X_train, X_test, y_train, y_test, weight=True):\n",
    "    if weight==True:\n",
    "        w = 'balanced'\n",
    "    else:\n",
    "        w=None   \n",
    "    print(\"decission Tree\")\n",
    "    t = tree.DecisionTreeClassifier(class_weight=w)\n",
    "    t = t.fit(X_train, y_train)\n",
    "    print(\"accuracy_score: \", t.score(X_test, y_test))\n",
    "    print(\"balanced accuracy score\", balanced_accuracy_score(y_test, t.predict(X_test), adjusted=True))\n",
    "    print(\"decission tree depth=\", 20)\n",
    "    decision_tree = DecisionTreeClassifier(random_state=0, max_depth=29, class_weight=w)\n",
    "    decision_tree = decision_tree.fit(X_train, y_train)\n",
    "    print(\"accuracy_score: \", decision_tree.score(X_test, y_test))\n",
    "    print(\"balanced accuracy score\", balanced_accuracy_score(y_test, decision_tree.predict(X_test), adjusted=True))\n",
    "    #random forest:\n",
    "    print(\"random forest:\")\n",
    "    forest = RandomForestClassifier(n_estimators=500, class_weight=w)\n",
    "    forest.fit(X_train,y_train)\n",
    "    forest.predict(X_test)\n",
    "    forest.predict_proba(X_test)\n",
    "    print(\"accuracy_score: \", forest.score(X_test, y_test))\n",
    "    print(\"balanced accuracy score\", balanced_accuracy_score(y_test, forest.predict(X_test), adjusted=True))\n",
    "\n",
    "def get_data():\n",
    "    df = pd.read_csv('feature_list_color.csv')\n",
    "    labels_unedited = np.array(df['ID_GATTUNG'])\n",
    "    df =df.drop(columns=['ID_GATTUNG'])\n",
    "    features = []  \n",
    "    # Iterate over each row\n",
    "    for rows in df.itertuples():      \n",
    "        # append the list to the final list\n",
    "        features.append(list(rows[1:]))\n",
    "    return features, labels_unedited\n",
    "db =db_settings.db(autocommit=False)\n",
    "req_families = \"\"\"SELECT * FROM lidar_proj.familien\"\"\"\n",
    "req_order = \"\"\"SELECT * FROM lidar_proj.ordnungen\"\"\"\n",
    "req_class = \"\"\"SELECT * FROM lidar_proj.klassen\"\"\"\n",
    "req_gattung = \"\"\"SELECT * FROM lidar_proj.gattungen\"\"\"\n",
    "\n",
    "df_families = db.export_to_pandas(req_families)\n",
    "df_order = db.export_to_pandas(req_order)\n",
    "df_class = db.export_to_pandas(req_class)\n",
    "df_gattung = db.export_to_pandas(req_gattung)\n",
    "\n",
    "df_families.set_index(\"ID\", drop=True, inplace=True)\n",
    "df_order.set_index(\"ID\", drop=True, inplace=True)\n",
    "df_class.set_index(\"ID\", drop=True, inplace=True)\n",
    "df_gattung.set_index(\"ID\", drop=True, inplace=True)\n",
    "global dict_gattung\n",
    "global dict_families\n",
    "global dict_order\n",
    "global dict_class\n",
    "\n",
    "dict_gattung =df_gattung.to_dict(orient=\"index\")\n",
    "\n",
    "dict_families =df_families.to_dict(orient=\"index\")\n",
    "dict_order =df_order.to_dict(orient=\"index\")\n",
    "dict_class =df_class.to_dict(orient=\"index\")\n",
    "print(dict_gattung[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d884159f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 17, 2: 7526, 3: 996, 4: 224, 6: 2, 7: 174, 8: 74, 9: 1, 10: 775, 11: 4, 15: 1, 16: 1193, 17: 31, 18: 178, 19: 13, 21: 10, 23: 1, 24: 17, 25: 7, 26: 13, 31: 20, 32: 1211, 33: 150, 35: 1, 36: 1, 37: 52, 38: 3, 39: 1, 40: 6, 41: 3, 42: 7, 45: 3, 46: 7, 47: 39, 48: 139, 49: 6, 50: 2, 51: 38, 52: 1, 54: 1, 55: 1, 57: 5, 58: 2, 62: 1, 63: 381, 64: 74, 65: 1, 69: 848, 70: 380, 71: 652, 72: 122, 73: 49, 75: 2, 77: 5, 79: 1, 80: 125, 81: 1690, 82: 82, 83: 21, 85: 8, 86: 469, 87: 1, 88: 1, 89: 1963, 90: 1418, 92: 10, 94: 169, 95: 42, 99: 79, 100: 24, 102: 267, 103: 172, 105: 1, 106: 1, 108: 6, 109: 1, 111: 1, 113: 6, 115: 3091, 116: 8613}\n"
     ]
    }
   ],
   "source": [
    "all_features, labels_unedited =get_data()\n",
    "#labels_unedited = np.array(list(map(get_family, labels_unedited)))\n",
    "all_features= np.array(all_features)\n",
    "l, l_num = np.unique(labels_unedited, return_counts=True)\n",
    "count_dict = dict(zip(l, l_num))\n",
    "print(count_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b27db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 10, 16, 32, 63, 69, 70, 71, 81, 86, 89, 90, 102, 115, 116]\n",
      "2   7526\n",
      "3   996\n",
      "4   224\n",
      "10   775\n",
      "16   1193\n",
      "32   1211\n",
      "63   381\n",
      "69   848\n",
      "70   380\n",
      "71   652\n",
      "81   1690\n",
      "86   469\n",
      "89   1963\n",
      "90   1418\n",
      "102   267\n",
      "115   3091\n",
      "116   8613\n"
     ]
    }
   ],
   "source": [
    "n = 200\n",
    "\n",
    "used_labels = []\n",
    "for key in count_dict.keys():\n",
    "    if count_dict[key] >= n:\n",
    "        used_labels.append(key)\n",
    "print(used_labels)\n",
    "data = {}\n",
    "for l in used_labels:\n",
    "    data[l] = all_features[labels_unedited == l]\n",
    "for key in data.keys():\n",
    "    print(key,\" \", len(data[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2adbfa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31697, 160) (31697,)\n",
      "labels train set {0: 5065, 1: 642, 2: 162, 3: 512, 4: 799, 5: 813, 6: 249, 7: 557, 8: 260, 9: 431, 10: 1092, 11: 314, 12: 1361, 13: 941, 14: 172, 15: 2101, 16: 5765}\n",
      "labels test set {0: 2461, 1: 354, 2: 62, 3: 263, 4: 394, 5: 398, 6: 132, 7: 291, 8: 120, 9: 221, 10: 598, 11: 155, 12: 602, 13: 477, 14: 95, 15: 990, 16: 2848}\n",
      "decission Tree\n",
      "accuracy_score:  0.18153140235159163\n",
      "balanced accuracy score 0.037873403886445\n",
      "decission tree depth= 20\n",
      "accuracy_score:  0.1797151323965204\n",
      "balanced accuracy score 0.044285284301403396\n",
      "random forest:\n",
      "accuracy_score:  0.332855367555683\n",
      "balanced accuracy score 0.03725103128263693\n"
     ]
    }
   ],
   "source": [
    "#unbaanced:\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for key in data.keys():\n",
    "    features +=list(data[key])\n",
    "    labels += [key for i in range(len(data[key]))]\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "labels, translator =scale_y(labels)\n",
    "labels = np.array(labels)\n",
    "print(features.shape, labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "l, l_num = np.unique(y_train, return_counts=True)\n",
    "print(\"labels train set\", dict(zip(l, l_num)))\n",
    "l, l_num = np.unique(y_test, return_counts=True)\n",
    "print(\"labels test set\", dict(zip(l, l_num)))\n",
    "\n",
    "train(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3eb486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3400, 160) (3400,)\n",
      "labels train set {0: 128, 1: 128, 2: 121, 3: 142, 4: 134, 5: 126, 6: 143, 7: 139, 8: 135, 9: 137, 10: 141, 11: 139, 12: 131, 13: 136, 14: 135, 15: 134, 16: 129}\n",
      "labels test set {0: 72, 1: 72, 2: 79, 3: 58, 4: 66, 5: 74, 6: 57, 7: 61, 8: 65, 9: 63, 10: 59, 11: 61, 12: 69, 13: 64, 14: 65, 15: 66, 16: 71}\n",
      "decission Tree\n",
      "accuracy_score:  0.23707664884135474\n",
      "balanced accuracy score 0.18959227156574496\n",
      "decission tree depth= 20\n",
      "accuracy_score:  0.24777183600713013\n",
      "balanced accuracy score 0.20025107022096353\n",
      "random forest:\n",
      "accuracy_score:  0.3065953654188948\n",
      "balanced accuracy score 0.26523662468546044\n"
     ]
    }
   ],
   "source": [
    "#balanced mx size 150:\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for key in data.keys():\n",
    "\n",
    "    if len(data[key]) > n:\n",
    "        idx = np.random.randint(len(data[key]) -1, size=n)\n",
    "        features_downsampled =data[key][idx,:]  \n",
    "\n",
    "        features +=list(features_downsampled)\n",
    "        labels += [key for i in range(len(features_downsampled))]\n",
    "    else:\n",
    "        features +=list(data[key])\n",
    "        labels += [key for i in range(len(data[key]))]\n",
    "\n",
    "        \n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "labels, translator =scale_y(labels)\n",
    "labels = np.array(labels)\n",
    "print(features.shape, labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "l, l_num = np.unique(y_train, return_counts=True)\n",
    "print(\"labels train set\", dict(zip(l, l_num)))\n",
    "l, l_num = np.unique(y_test, return_counts=True)\n",
    "print(\"labels test set\", dict(zip(l, l_num)))\n",
    "\n",
    "train(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee9822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 17, 2: 7526, 3: 996, 4: 224, 6: 2, 7: 174, 8: 74, 9: 1, 10: 775, 11: 4, 15: 1, 16: 1193, 17: 31, 18: 178, 19: 13, 21: 10, 23: 1, 24: 17, 25: 7, 26: 13, 31: 20, 32: 1211, 33: 150, 35: 1, 36: 1, 37: 52, 38: 3, 39: 1, 40: 6, 41: 3, 42: 7, 45: 3, 46: 7, 47: 39, 48: 139, 49: 6, 50: 2, 51: 38, 52: 1, 54: 1, 55: 1, 57: 5, 58: 2, 62: 1, 63: 381, 64: 74, 65: 1, 69: 848, 70: 380, 71: 652, 72: 122, 73: 49, 75: 2, 77: 5, 79: 1, 80: 125, 81: 1690, 82: 82, 83: 21, 85: 8, 86: 469, 87: 1, 88: 1, 89: 1963, 90: 1418, 92: 10, 94: 169, 95: 42, 99: 79, 100: 24, 102: 267, 103: 172, 105: 1, 106: 1, 108: 6, 109: 1, 111: 1, 113: 6, 115: 3091, 116: 8613}\n"
     ]
    }
   ],
   "source": [
    "all_features, labels_unedited =get_data()\n",
    "all_features= np.array(all_features)\n",
    "l, l_num = np.unique(labels_unedited, return_counts=True)\n",
    "count_dict = dict(zip(l, l_num))\n",
    "print(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7c7567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 17, 2: 7526, 3: 996, 4: 224, 6: 2, 7: 174, 8: 74, 9: 1, 10: 775, 11: 4, 15: 1, 16: 1193, 17: 31, 18: 178, 19: 13, 21: 10, 23: 1, 24: 17, 25: 7, 26: 13, 31: 20, 32: 1211, 33: 150, 35: 1, 36: 1, 37: 52, 38: 3, 39: 1, 40: 6, 41: 3, 42: 7, 45: 3, 46: 7, 47: 39, 48: 139, 49: 6, 50: 2, 51: 38, 52: 1, 54: 1, 55: 1, 57: 5, 58: 2, 62: 1, 63: 381, 64: 74, 65: 1, 69: 848, 70: 380, 71: 652, 72: 122, 73: 49, 75: 2, 77: 5, 79: 1, 80: 125, 81: 1690, 82: 82, 83: 21, 85: 8, 86: 469, 87: 1, 88: 1, 89: 1963, 90: 1418, 92: 10, 94: 169, 95: 42, 99: 79, 100: 24, 102: 267, 103: 172, 105: 1, 106: 1, 108: 6, 109: 1, 111: 1, 113: 6, 115: 3091, 116: 8613}\n",
      "{2: 7526, 16: 1193, 32: 1211, 81: 1690, 115: 3091, 116: 8613}\n"
     ]
    }
   ],
   "source": [
    "all_features, labels_unedited =get_data()\n",
    "#labels_unedited = np.array(list(map(get_family, labels_unedited)))\n",
    "all_features= np.array(all_features)\n",
    "l, l_num = np.unique(labels_unedited, return_counts=True)\n",
    "count_dict = dict(zip(l, l_num))\n",
    "print(count_dict)\n",
    "\n",
    "used_keys_fam = [1, 2, 6, 13, 46, 47]\n",
    "used_keys_fam = [1, 13]\n",
    "used_keys_gatt = [2, 16, 32, 81, 115,116]\n",
    "familys = {}\n",
    "for key in used_keys_gatt:\n",
    "    familys[key] = count_dict[key]\n",
    "print(familys)\n",
    "n = 223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20d17d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 16, 32, 81, 115, 116]\n",
      "2   7526\n",
      "16   1193\n",
      "32   1211\n",
      "81   1690\n",
      "115   3091\n",
      "116   8613\n",
      "(7193, 160) (7193,)\n",
      "labels train set {0: 786, 1: 799, 2: 803, 3: 812, 4: 804, 5: 815}\n",
      "labels test set {0: 414, 1: 394, 2: 397, 3: 388, 4: 396, 5: 385}\n",
      "decission Tree\n",
      "accuracy_score:  0.38500421229991577\n",
      "balanced accuracy score 0.2620273407732192\n",
      "decission tree depth= 20\n",
      "accuracy_score:  0.3887952822240944\n",
      "balanced accuracy score 0.2665666569114677\n",
      "random forest:\n",
      "accuracy_score:  0.4953664700926706\n",
      "balanced accuracy score 0.39492094090726015\n"
     ]
    }
   ],
   "source": [
    "n = 1200\n",
    "\n",
    "used_labels = used_keys_gatt\n",
    "#for key in count_dict.keys():\n",
    "#    if count_dict[key] >= n:\n",
    "#        used_labels.append(key)\n",
    "print(used_labels)\n",
    "data = {}\n",
    "for l in used_labels:\n",
    "    data[l] = all_features[labels_unedited == l]\n",
    "for key in data.keys():\n",
    "    print(key,\" \", len(data[key]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for key in data.keys():\n",
    "\n",
    "    if len(data[key]) > n:\n",
    "        idx = np.random.randint(len(data[key]) -1, size=n)\n",
    "        features_downsampled =data[key][idx,:]  \n",
    "\n",
    "        features +=list(features_downsampled)\n",
    "        labels += [key for i in range(len(features_downsampled))]\n",
    "    else:\n",
    "        features +=list(data[key])\n",
    "        labels += [key for i in range(len(data[key]))]\n",
    "\n",
    "        \n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "labels, translator =scale_y(labels)\n",
    "labels = np.array(labels)\n",
    "print(features.shape, labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "l, l_num = np.unique(y_train, return_counts=True)\n",
    "print(\"labels train set\", dict(zip(l, l_num)))\n",
    "l, l_num = np.unique(y_test, return_counts=True)\n",
    "print(\"labels test set\", dict(zip(l, l_num)))\n",
    "\n",
    "train(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f25f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec28442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
